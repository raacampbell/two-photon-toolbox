
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>Pre-Processing</title><meta name="generator" content="MATLAB 8.1"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2013-06-19"><meta name="DC.source" content="imagingAnalysis_preprocess.m"><style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,sub,sup,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#005fce; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img { margin-bottom:0px; } 

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, tt, code { font-size:12px; }
pre { margin:0px 0px 20px; }
pre.error { color:red; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }





  </style></head><body><div class="content"><h1>Pre-Processing</h1><!--introduction--><p>This guide continues from the <a href="imagingAnalysis_importing.html">importing</a> tutorial. The following steps should work correctly regardless of which software was used to generate the data and record the stimulus parameters. The following are covered here:</p><!--/introduction--><h2>Contents</h2><div><ul><li><a href="#1">De-noising</a></li><li><a href="#2">Motion correction</a></li><li><a href="#3">Finding the Region Of Interest (ROI)</a></li><li><a href="#8">Photo-Bleach Correction</a></li><li><a href="#13">Now What?</a></li></ul></div><h2>De-noising<a name="1"></a></h2><p>You might want to de-noise your data and replace the .mat files from the import with the de-noised (i.e. smoothed) versions. There are various ways of de-noising 2-photon data. Some are quite advanced. As an example, the <a href="twoPImportBatch.html"><tt>twoPImportBatch</tt></a> function provides the option of running a simply smoothing filter on each frame independently. It does this by an optional call to the <a href="filterImageStack.html"><tt>filterImageStack</tt></a> function during import-time. The filtering performed by this function is rather simplistic and is not recommended for most purposes. It simply serves as an example of what's possible. In general, such smoothing only serves to produce response movies that look nicer. The smoothing doesn't improve the quality if the data which you actually analyse (and it may even make it worse). This is because what's actually analysed is the mean evoked response of each ROI or neuron. Conducting your analyses with the goal of producing movies that look good is not something you want to be doing in most circumstances. The reader interested in de-noising could consult: <a href="http://www.plosone.org/article/info:doi/10.1371/journal.pone.0020490"><tt>http://www.plosone.org/article/info:doi/10.1371/journal.pone.0020490</tt></a></p><h2>Motion correction<a name="2"></a></h2><p>For <i>in vivo</i> recordings, motion correction is often critical since most data analyses require the same bit of brain to be in the same location across trials. This allows the user to draw an ROI around a brain region in one trial and know that the same bit of brain is within that fixed ROI in all other trials. Thus, the stimulus-evoked dF/F of the ROI can be calculated on each trial and so a tuning curve can be drawn.</p><p>Unfortunately, it is common for the brain to drift over the course of an experiment. If the brain has drifted in <i>z</i> then obviously no correction is possible off-line. Recordings with a lot of <i>z</i>-motion should be excluded. Lateral drift, however, can be corrected as can moderate non-linear deformations (which we find to be quite common our mushroom body recordings).</p><p>Image sequences are aligned in two steps. First of all, <a href="alignStack.html"><tt>alignStack</tt></a> corrects all frames within one stimulus repeat. Then  <a href="alignRepeats.html"><tt>alignRepeats</tt></a> aligns all frames across different trials.</p><p>See <a href="alignStack.html"><tt>alignStack</tt></a> for a list of the various different motion-correction algorithms available. The <tt>fftquick</tt> is a quick, 2-D, sub-pixel translation correction. In many cases it is sufficient. If a brain exhibits significant <i>z</i>-motion then chances are you can't correct it. If, on the other hand, what you're seeing is motion in the <i>x</i>/_y_ plane, then some degree of correction is often possible. Sometimes the results are quite dramatic. The key to getting a good motion correction is identify what sort of motion you're seeing and then apply the right algorithm to fix this. The wrong aglorithm can make things worse. Examaine the image stack before and after correction to decide how to proceed. This is best achieved by experience. See the Examples section of this Help to read through a worked example. Also, there are examples in the help sections of <a href="alignStack.html"><tt>alignStack</tt></a> and  <a href="regParams.html"><tt>regParams</tt></a>.</p><h2>Finding the Region Of Interest (ROI)<a name="3"></a></h2><p>In our recordings the flourescent brain tissue is surrounded by non-flourescent background. This step uses the <a href="ROI_batch.html">ROI_batch</a> function to separate brain from background: <tt>ROI_batch(exampleObject)</tt>. By default we have the same ROI for each trial, but this is optional. This function adds a field called <tt>ROI</tt> to each trial. The first ROI contains:</p><pre class="codeinput">cd <span class="string">~/work/Matlab_Scripts/ImagingAnalysis/examples/TSeries-02032010-1558-002</span>
load <span class="string">exampleData</span>
ROI_batch(exampleData);
</pre><pre class="codeoutput">Applying ROI #1 to all 3 recordings
Calculating background intensity...
</pre><pre class="codeinput">exampleData(1).ROI
</pre><pre class="codeoutput">
ans = 

              level: 0.0269
                roi: [260x348 logical]
              notes: 'auto-detected ROI. DO NOT DELETE ME'
    backgroundLevel: 0.0045

</pre><p>This ROI segragates brain from background and <b>should not be deleted</b>, as it is used in later analysis steps. The <tt>ROI.roi</tt> mask itself is a matrix of ones and zeros. Here, the region inside the ROI is shown in white and outside in black:</p><pre class="codeinput">clf
imagesc(exampleData(1).ROI.roi)
axis <span class="string">equal</span> <span class="string">tight</span>, colormap <span class="string">gray</span>
</pre><img vspace="5" hspace="5" src="/home/rob/Dropbox/home/work/Matlab_Scripts/ImagingAnalysis/html/imagingAnalysis_preprocess_01.png" alt=""> <p>We can now show the baseline image minus the background by doing:</p><pre class="codeinput">clf
imagesc(exampleData(1).baselineImage .* exampleData(1).ROI.roi)
axis <span class="string">equal</span> <span class="string">off</span>
</pre><img vspace="5" hspace="5" src="/home/rob/Dropbox/home/work/Matlab_Scripts/ImagingAnalysis/html/imagingAnalysis_preprocess_02.png" alt=""> <p>The region outside the ROI is considered to be "background" and its mean is subtracted from all pixel values when calculating the dF/F. It is worth noting that if some brain is present in the background then this could significantly bias the calculation. If you are recording from, say, cortex then you probably don't want to separate brain from background since everywhere is brain. However, you will need to create suitable data in ROI(1) so that analysis functions have an estimate of the background intensity.</p><h2>Photo-Bleach Correction<a name="8"></a></h2><p>Laser scanning bleaches the flourescent indicator and so pixel intensity will tend to decrease over the recording period. This decrease isn't interesting and so we try to correct for it if it's significant. This process is known as photo-bleach correction and is achieved by running: <tt>doPhotoBleachCorrection(exampleData)</tt></p><p>The correction is fitted to the response time course (i.e. the mean of each frame over time). First the frames which may contain a significant response are removed (for this reason we need the stimulus onset and offset times in the <tt>.stim</tt> field of the object) and replaced by a linear interpolation. The trace is then heavily smoothed (i.e. low-pass filtered). This smoothed trace is considered to contain only non-stimulus-related features and is subtracted from the original time series. The correction procedure does not replace the data on the disk, instead it stores the correction curve in the <tt>twoPhoton</tt> object and applies it each time the data are loaded. This makes it easy to change the correction at a future time if needed, perhaps because the above correction algorithm doesn't work for you.</p><p>Usually one has to scan for long periods (e.g. over a minute) to see significant bleaching. If trials are shorter than this, the bleaching may well be insignificant and so it makes little sense to try to correct for it. Because evoked dF/F is calculated independently on each trial, photo-bleaching across trials is automaticaly taken care of.</p><p>It is easy to examine the result of the photo-bleach correction using the following function call.</p><pre class="codeinput">showPhotoBleachFit(exampleData(1))
</pre><img vspace="5" hspace="5" src="/home/rob/Dropbox/home/work/Matlab_Scripts/ImagingAnalysis/html/imagingAnalysis_preprocess_03.png" alt=""> <p>Here we have chosen not to apply a correction because the response massively outweighs any possible bleaching that might occur. Note that signal intensity rises over the first 2 or 3 frames. This is due to the Pockels cell.</p><h2>Now What?<a name="13"></a></h2><p>The data are now saved and pre-processed (motion-corrected and photo-bleach-corrected) and you can move on to the real analysis. You will now want to do one or more of the following:</p><div><ul><li>Work with the whole-brain ROI to produce summary statistics, images, and movies.</li><li>Use <a href="ROI_add.html"><tt>ROI_add</tt></a> to define one or more ROIs, which can then be compared.</li><li>Manually identify neuronal cell bodies to <a href="imagingAnalysis_neurons.html">explore patterns of neuronal activation</a>.</li></ul></div><p class="footer"><br><a href="http://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2013a</a><br></p></div><!--
##### SOURCE BEGIN #####
%% Pre-Processing
%
% This guide continues from the <imagingAnalysis_importing.html
% importing> tutorial. The following steps should work correctly
% regardless of which software was used to generate the data and record the
% stimulus parameters. The following are covered here:
%
%
%% De-noising
% You might want to de-noise your data and replace the .mat files from
% the import with the de-noised (i.e. smoothed) versions. There are
% various ways of de-noising 2-photon data. Some are quite
% advanced. As an example, the <twoPImportBatch.html
% |twoPImportBatch|> function provides the option of running a simply
% smoothing filter on each frame independently. It does this by an
% optional call to the <filterImageStack.html |filterImageStack|>
% function during import-time. The filtering performed by this
% function is rather simplistic and is not recommended for most
% purposes. It simply serves as an example of what's possible. In
% general, such smoothing only serves to produce response movies that
% look nicer. The smoothing doesn't improve the quality if the data
% which you actually analyse (and it may even make it worse). This is
% because what's actually analysed is the mean evoked response of each
% ROI or neuron. Conducting your analyses with the goal of producing
% movies that look good is not something you want to be doing in most
% circumstances. The reader interested in de-noising could consult:
% <http://www.plosone.org/article/info:doi/10.1371/journal.pone.0020490
% |http://www.plosone.org/article/info:doi/10.1371/journal.pone.0020490|>
%
%
%% Motion correction
% For _in vivo_ recordings, motion correction is often critical since
% most data analyses require the same bit of brain to be in
% the same location across trials. This allows the user to draw an
% ROI around a brain region in one trial and know that the same bit
% of brain is within that fixed ROI in all other trials. Thus, the
% stimulus-evoked dF/F of the ROI can be calculated on each trial
% and so a tuning curve can be drawn. 
%
% Unfortunately, it is common for the brain to drift over the course
% of an experiment. If the brain has drifted in _z_ then obviously no
% correction is possible off-line. Recordings with a lot of _z_-motion should
% be excluded. Lateral drift, however, can be corrected as can
% moderate non-linear deformations (which we find to be quite
% common our mushroom body recordings). 
%
% Image sequences are aligned in two steps. First of all,
% <alignStack.html |alignStack|> corrects all frames within one
% stimulus repeat. Then  <alignRepeats.html |alignRepeats|> aligns
% all frames across different trials. 
%
% See <alignStack.html |alignStack|> for a list of the various
% different motion-correction algorithms available. The |fftquick|
% is a quick, 2-D, sub-pixel translation correction. In many cases
% it is sufficient. If a brain exhibits significant _z_-motion then
% chances are you can't correct it. If, on the other hand, what
% you're seeing is motion in the _x_/_y_ plane, then some
% degree of correction is often possible. Sometimes the results are
% quite dramatic. The key to getting a good motion correction is
% identify what sort of motion you're seeing and then apply the
% right algorithm to fix this. The wrong aglorithm can make things
% worse. Examaine the image stack before and after correction to
% decide how to proceed. This is best achieved by
% experience. See the Examples section of this Help to read through
% a worked example. Also, there are examples in the help sections
% of <alignStack.html |alignStack|> and  <regParams.html |regParams|>.
%
%% Finding the Region Of Interest (ROI)
% In our recordings the flourescent brain tissue is surrounded by
% non-flourescent background. This step uses the <ROI_batch.html
% ROI_batch> function to separate brain from background:
% |ROI_batch(exampleObject)|. By default we have the same ROI for
% each trial, but this is optional. This function adds a field
% called |ROI| to each trial. The first ROI contains:
cd ~/work/Matlab_Scripts/ImagingAnalysis/examples/TSeries-02032010-1558-002
load exampleData
ROI_batch(exampleData);

%%
exampleData(1).ROI     

%%
% This ROI segragates brain from background and *should not be
% deleted*, as it is used in later analysis steps. The |ROI.roi| mask
% itself is a matrix of ones and zeros. Here, the region inside the
% ROI is shown in white and outside in black:
clf
imagesc(exampleData(1).ROI.roi)
axis equal tight, colormap gray 

%%
% We can now show the baseline image minus the background by doing:
clf
imagesc(exampleData(1).baselineImage .* exampleData(1).ROI.roi)
axis equal off

%%
% The region outside the ROI is considered to be "background" and
% its mean is subtracted from all pixel values when calculating the
% dF/F. It is worth noting that if some brain is present in the
% background then this could significantly bias the calculation. If
% you are recording from, say, cortex then you probably don't want
% to separate brain from background since everywhere is
% brain. However, you will need to create suitable data in ROI(1)
% so that analysis functions have an estimate of the background
% intensity. 
        
%% Photo-Bleach Correction
% Laser scanning bleaches the flourescent indicator and so pixel
% intensity will tend to decrease over the recording period. This
% decrease isn't interesting and so we try to correct for it if it's
% significant. This process is known as photo-bleach correction and is
% achieved by running: |doPhotoBleachCorrection(exampleData)|
%
%%
% The correction is fitted to the response time course (i.e. the mean
% of each frame over time). First the frames which may contain a
% significant response are removed (for this reason we need the
% stimulus onset and offset times in the |.stim| field of the object)
% and replaced by a linear interpolation. The trace is then heavily
% smoothed (i.e. low-pass filtered). This smoothed trace is considered
% to contain only non-stimulus-related features and is subtracted from
% the original time series. The correction procedure does not replace
% the data on the disk, instead it stores the correction curve in the
% |twoPhoton| object and applies it each time the data are
% loaded. This makes it easy to change the correction at a future time
% if needed, perhaps because the above correction algorithm doesn't
% work for you. 

%%
% Usually one has to scan for long periods (e.g. over a minute) to
% see significant bleaching. If trials are shorter than this, the
% bleaching may well be insignificant and so it makes little sense
% to try to correct for it. Because evoked dF/F is calculated
% independently on each trial, photo-bleaching across trials is
% automaticaly taken care of. 

%%
% It is easy to examine the result of the photo-bleach correction
% using the following function call. 
showPhotoBleachFit(exampleData(1)) 

%% 
% Here we have chosen not to apply a correction because the response
% massively outweighs any possible bleaching that might occur. Note
% that signal intensity rises over the first 2 or 3 frames. This is
% due to the Pockels cell. 


%% Now What?
% The data are now saved and pre-processed (motion-corrected and
% photo-bleach-corrected) and you can move on to the real
% analysis. You will now want to do one or more of the following:
%
% * Work with the whole-brain ROI to produce summary statistics,
% images, and movies. 
% * Use <ROI_add.html |ROI_add|> to define one or more ROIs, which
% can then be compared.
% * Manually identify neuronal cell bodies to
% <imagingAnalysis_neurons.html explore patterns of neuronal activation>.



##### SOURCE END #####
--></body></html>